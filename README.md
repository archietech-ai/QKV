# QKV

## Simple Self attention

We want to use a query matrix and multiply that in key matrices. In a simple term it will be like:
![image](https://github.com/user-attachments/assets/8f71f2cb-e96d-49bd-a688-679ad6e1c5a9)

But in a bit more realistic way first we calculate the "attention weigh". I have shown that in two steps:

### Step 1:


![image](https://github.com/user-attachments/assets/3183ec2c-7f6f-4ba5-8847-cefcf81af34b)

### Step 2:

![image](https://github.com/user-attachments/assets/de84c53b-cf77-4632-a28f-4a1407c83194)


## Self attention

Now we want to perform real self-attention like the way it is implemented in the original transformer.

![image](https://github.com/user-attachments/assets/2036638e-8dc2-4e93-8c20-c81c983af9b4)

![image](https://github.com/user-attachments/assets/694428ff-4e9a-4b38-8c0d-54a118d93595)





##  Self attention


